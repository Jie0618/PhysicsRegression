# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.
#
import math, time, copy
import numpy as np
import torch
import signal
from collections import defaultdict
from symbolicregression.metrics import compute_metrics
from sklearn.base import BaseEstimator
import symbolicregression.model.utils_wrapper as utils_wrapper
import traceback
from sklearn import feature_selection 
from symbolicregression.envs.generators import Node
from copy import deepcopy

def corr(X, y, epsilon=1e-10):
    """
    X : shape n*d
    y : shape n
    """
    cov = (y @ X)/len(y) - y.mean()*X.mean(axis=0)
    corr = cov / (epsilon + X.std(axis=0) * y.std())
    return corr

def get_top_k_features(X, y, k=10):
    if y.ndim==2:
        y=y[:,0]
    if X.shape[1]<=k:
        return [i for i in range(X.shape[1])]
    else:
        kbest = feature_selection.SelectKBest(feature_selection.r_regression, k=k)
        kbest.fit(X, y)
        scores = kbest.scores_
        #scores = corr(X, y)
        top_features = np.argsort(-np.abs(scores))
        print("keeping only the top-{} features. Order was {}".format(k, top_features))
        return list(top_features[:k])

def exchange_node_values(tree, dico):
    new_tree = copy.deepcopy(tree)
    for (old, new) in dico.items():
        new_tree.replace_node_value(old, new)
    return new_tree

class SymbolicTransformerRegressor(BaseEstimator):

    def __init__(self,
                model=None,
                max_input_points=10000,
                max_number_bags=-1,
                stop_refinement_after=1,
                n_trees_to_refine=1,
                rescale=True
                ):

        self.max_input_points = max_input_points
        self.max_number_bags = max_number_bags
        self.model = model
        self.stop_refinement_after = stop_refinement_after
        self.n_trees_to_refine = n_trees_to_refine
        self.rescale = rescale

    def set_args(self, args={}):
        for arg, val in args.items():
            assert hasattr(self, arg), "{} arg does not exist".format(arg)
            setattr(self, arg, val)

    def fit(
        self,
        X,
        Y,
        hints,
        verbose=False,
        refinement_types=["id"],
    ):
        self.start_fit = time.time()

        if not isinstance(X, list):
            X = [X]
            Y = [Y]
            hints = [[h] for h in hints]
        n_datasets = len(X)

        self.top_k_features = [None for _ in range(n_datasets)]
        for i in range(n_datasets):
            self.top_k_features[i] = get_top_k_features(X[i], Y[i], k=self.model.env.params.max_input_dimension)
            X[i] = X[i][:, self.top_k_features[i]]
    
        scaler = utils_wrapper.StandardScaler() if self.rescale else None
        scale_params = {}
        if scaler is not None:
            scaled_X = []
            for i, x in enumerate(X):
                scaled_X.append(scaler.fit_transform(x))
                scale_params[i]=scaler.get_params()
        else:
            scaled_X = X

        inputs, inputs_ids, new_hints = [], [], [[] for i in range(len(hints))]
        for seq_id in range(len(scaled_X)):
            for seq_l in range(len(scaled_X[seq_id])):
                y_seq = Y[seq_id]
                if len(y_seq.shape)==1:
                    y_seq = np.expand_dims(y_seq,-1)
                if seq_l % self.max_input_points == 0:
                    inputs.append([])
                    inputs_ids.append(seq_id)
                    for i,h in enumerate(new_hints):
                        h.append(copy.deepcopy(hints[i][seq_id]))
                inputs[-1].append([scaled_X[seq_id][seq_l], y_seq[seq_l]])

        #is this only valid for single inference?
        if self.max_number_bags>0:
            inputs = inputs[:self.max_number_bags]
            inputs_ids = inputs_ids[:self.max_number_bags]
            new_hints = [
                h[:self.max_number_bags] for h in new_hints
            ]

        forward_time=time.time()
        outputs = self.model(inputs, new_hints)  ##Forward transformer: returns predicted functions
        if verbose: print("Finished forward in {} secs".format(time.time()-forward_time))

        outputs, _, _ = outputs

        candidates = defaultdict(list)
        assert len(inputs) == len(outputs), "Problem with inputs and outputs"
        for i in range(len(inputs)):
            input_id = inputs_ids[i]
            candidate = outputs[i]
            candidates[input_id].extend(candidate)
        assert len(candidates.keys()) == n_datasets, "issue with n_can={}, n_can_ppl={}, n_data={}".format(
            len(candidates.keys()), n_datasets,
        )
            
        self.tree = {}
        for input_id, candidates_id in candidates.items():
            if len(candidates_id)==0: 
                self.tree[input_id]=None
                continue

            if scaler is not None:
                rescaled_candidates = [scaler.rescale_function(self.model.env, c, *scale_params[input_id]) for c in candidates_id]
            else: 
                rescaled_candidates = candidates_id
            refined_candidates = self.refine(X[input_id], Y[input_id], rescaled_candidates, verbose, refinement_types)
            self.tree[input_id] = refined_candidates

    @torch.no_grad()
    def evaluate_tree(self, tree, X, y, metric):
        try:
            #use abs
            use_abs = tree.params.use_abs
            tree.params.use_abs = True
            y_tilde = tree.val(X).reshape((-1, 1))
            tree.params.use_abs = use_abs
        except:
            y_tilde = np.array([np.nan]).repeat(X.shape[0])

        metrics = compute_metrics({"true": [y], "predicted": [y_tilde], "predicted_tree": [tree]}, metrics=metric)
        return metrics[metric][0]

    def order_candidates(self, X, y, candidates, metric="_mse", verbose=False):
        scores = []
        for candidate in candidates:
            if metric not in candidate:
                score = self.evaluate_tree(candidate["predicted_tree"], X, y, metric)
                if math.isnan(score): 
                    score = np.infty if metric.startswith("_") else -np.infty
            else:
                score = candidates[metric]
            scores.append(score)
        ordered_idx = np.argsort(scores)  
        if not metric.startswith("_"): ordered_idx=list(reversed(ordered_idx))
        candidates = [candidates[i] for i in ordered_idx]
        return candidates

    def refine(self, X, y, candidates, verbose, refinement_types):
        env = self.model.env
        generator = self.model.env.generator
        refined_candidates = []
        
        ## For skeleton model
        for i, candidate in enumerate(candidates):
            candidate_skeleton, candidate_constants =  generator.function_to_skeleton(candidate, constants_with_idx=True)
            if "CONSTANT" in candidate_constants:
                candidates[i] = generator.wrap_equation_floats(candidate_skeleton, np.random.randn(len(candidate_constants)))

        candidates = [
            {
                "refinement_type": "NoRef", 
                "predicted_tree": candidate, 
                "time": time.time()-self.start_fit,
            } for candidate in candidates
        ]
        candidates = self.order_candidates(X, y, candidates, metric="_mse", verbose=verbose)

        ## REMOVE SKELETON DUPLICATAS
        skeleton_candidates, candidates_to_remove = {}, []
        for i, candidate in enumerate(candidates):
            skeleton_candidate, _ = generator.function_to_skeleton(candidate["predicted_tree"], constants_with_idx=False)
            if skeleton_candidate.infix() in skeleton_candidates:
                candidates_to_remove.append(i)
            else:
                skeleton_candidates[skeleton_candidate.infix()]=1
        if verbose: print("Removed {}/{} skeleton duplicata".format(len(candidates_to_remove), len(candidates)))

        candidates = [candidates[i] for i in range(len(candidates)) if i not in candidates_to_remove]
        if self.n_trees_to_refine>0:
            candidates_to_refine = candidates[:self.n_trees_to_refine]
        else:
            candidates_to_refine = copy.deepcopy(candidates)

        for candidate in candidates_to_refine:
            refinement_strategy = utils_wrapper.BFGSRefinement()

            tree_to_refine = candidate["predicted_tree"]

            refined_candidate = self._safely_refine(X, y, tree_to_refine, refinement_types)

            if refined_candidate is not None:
                refined_candidates.append({ 
                        "refinement_type": "BFGS",
                        "predicted_tree": refined_candidate,
                        })            
        candidates.extend(refined_candidates)  
        candidates = self.order_candidates(X, y, candidates, metric="r2")

        for candidate in candidates:
            if "time" not in candidate:
                candidate["time"]=time.time()-self.start_fit
        return candidates
  
    def _safely_refine(self, X, y, node_to_refine, safety_types=["id"]):

        refined_nodes = []

        for safely_type in safety_types:
            
            if safely_type == "id":
                safely_y = y
                root = node_to_refine
                refined_node = self._refine(X, safely_y, root) 
                refined_nodes.append(refined_node)

            elif safely_type == "neg":
                safely_y = deepcopy(y)
                safely_node = deepcopy(node_to_refine)
                root = Node("neg", self.model.env.params, children=[safely_node])
                root.unit = safely_node.unit
                refined_node = self._refine(X, safely_y, root) 
                refined_nodes.append(refined_node)

            elif safely_type == "inv":
                safely_y = 1 / deepcopy(y)
                safely_node = deepcopy(node_to_refine)
                root = Node("inv", self.model.env.params, children=[safely_node])
                root.unit = - safely_node.unit
                refined_node = self._refine(X, safely_y, root) 
                try:
                    refined_nodes.append(refined_node.children[0])
                except:
                    refined_nodes.append(safely_node)

            elif safely_type == "linear":
                safely_y = deepcopy(y)
                safely_node = deepcopy(node_to_refine)
                child1 = Node("0", self.model.env.params)
                child2 = Node("1", self.model.env.params)
                child3 = Node("mul", self.model.env.params, children=[child2, safely_node])
                root = Node("add", self.model.env.params, children=[child1, child3])
                child2.unit = np.zeros((5))
                child3.unit = safely_node.unit
                child1.unit = safely_node.unit
                root.unit = safely_node.unit
                refined_node = self._refine(X, safely_y, root) 
                refined_nodes.append(refined_node)

            elif safely_type == "safe":
                safely_y = y
                root = deepcopy(node_to_refine)
                self.model.env.generator.unify_const(root)
                self.model.env.generator.unify_const3(root)
                refined_node = self._refine(X, safely_y, root, ignore=[0,1,-1]) 
                refined_nodes.append(refined_node)
            
            elif safely_type == "safe-neg":
                safely_y = deepcopy(y)
                safely_node = deepcopy(node_to_refine)
                root = Node("neg", self.model.env.params, children=[safely_node])
                root.unit = safely_node.unit
                self.model.env.generator.unify_const(root)
                self.model.env.generator.unify_const3(root)
                refined_node = self._refine(X, safely_y, root, ignore=[0,1,-1]) 
                refined_nodes.append(refined_node)

            else:
                raise ValueError(f"{safely_type} is not permitted")
        
        refined_nodes = self.order_tree(X, y, refined_nodes)
        return refined_nodes[0]
    
    def _refine(self, X, y, node_to_refine, ignore=[]):
        generator = self.model.env.generator

        refinement_strategy = utils_wrapper.BFGSRefinement()
        
        try:
            node_skeleton, node_constants = generator.function_to_skeleton(
                node_to_refine, constants_with_idx=True, ignore=ignore
            )
            refined_node, refine_success = refinement_strategy.go(env=self.model.env, 
                                                    tree=node_skeleton, 
                                                    coeffs0=node_constants,
                                                    X=X,
                                                    y=y,
                                                    downsample=1024,
                                                    stop_after=1)
            
            assert refined_node is not None

        except:
            message = traceback.format_exc()
            refined_node = node_to_refine

        return refined_node
    
    def order_tree(self, X, y, trees, metric="_mse"):
        scores = []
        for tree in trees:
            score = self.evaluate_tree(tree, X, y, metric)
            if math.isnan(score): 
                score = np.infty if metric.startswith("_") else -np.infty
            scores.append(score)
        ordered_idx = np.argsort(scores)  
        if not metric.startswith("_"): ordered_idx=list(reversed(ordered_idx))
        trees = [trees[i] for i in ordered_idx]
        return trees
        


    def __str__(self):
        if hasattr(self, "tree"):
            for tree_idx in range(len(self.tree)):
                for gen in self.tree[tree_idx]:
                    print(gen)
        return "Transformer"

    def retrieve_refinements_types(self):
        return ["BFGS", "NoRef"]

    def exchange_tree_features(self):
        top_k_features = self.top_k_features
        for dataset_id, candidates in self.tree.items():
            exchanges = {}
            for i, feature in enumerate(top_k_features[dataset_id]):
                exchanges["x_{}".format(i)]="x_{}".format(feature)
            if candidates is None:continue
            for candidate in candidates:
                candidate["relabed_predicted_tree"] = exchange_node_values(candidate["predicted_tree"], exchanges)

    def retrieve_tree(self, refinement_type=None, dataset_idx=0, all_trees=False, with_infos=False):
        self.exchange_tree_features()
        if dataset_idx == -1: idxs = [_ for _ in range(len(self.tree))] 
        else: idxs = [dataset_idx]
        best_trees = []
        for idx in idxs:
            best_tree = copy.deepcopy(self.tree[idx])
            if best_tree and refinement_type is not None:
                best_tree = list(filter(lambda gen: gen["refinement_type"]==refinement_type, best_tree))
            if not best_tree:
                if with_infos:
                    best_trees.append(
                        {"predicted_tree": None, "refinement_type": refinement_type, "time": None, "perplexity": None, "relabed_predicted_tree": None}
                    )
                else:
                    best_trees.append(None)
            else:
                if with_infos:
                    if all_trees:
                        best_trees.append(best_tree)
                    else:
                        best_trees.append(best_tree[0])
                else:
                    if all_trees:
                        best_trees.append([best_tree[i]["predicted_tree"] for i in range(len(best_tree))])
                    else:
                        best_trees.append(best_tree[0]["predicted_tree"])
        if dataset_idx != -1: 
            return best_trees[0]
        else: return best_trees


    def predict(
            self, X, refinement_type=None, tree_idx=0, batch=False, 
            oracle_results=False, oracle_tree=None, merged_type=None, oracle_type=None
    ):        

        if not isinstance(X, list):
            X = [X]
        
        if oracle_results:
            for i in range(len(X)):
                X[i] = X[i][:,self.top_k_features[i]]

        else:
            for i in range(len(X)):
                X[i]=X[i][:,self.top_k_features[i]]

        res = []
        if batch:
            tree = self.retrieve_tree(refinement_type=refinement_type, dataset_idx = -1)
            for tree_idx in range(len(tree)):
                X_idx = X[tree_idx]
                if tree[tree_idx] is None: 
                    res.append(None)
                else:   
                    try:
                        #use abs
                        node = tree[tree_idx]
                        use_abs = node.params.use_abs
                        node.params.use_abs = True
                        y = node.val(X_idx).reshape((-1, 1))
                        node.params.use_abs = use_abs
                    except:
                        y = np.array([np.nan]).repeat(X_idx.shape[0])
                    res.append(y)
            return res
        
        elif oracle_results:

            tree = oracle_tree
            for tree_idx in range(len(tree)):
                X_idx = X[tree_idx]
                if tree[tree_idx] is None: 
                    res.append(None)
                else:   
                    try:
                        #use abs
                        node = tree[tree_idx]
                        use_abs = node.params.use_abs
                        node.params.use_abs = True
                        y = node.val(X_idx).reshape((-1, 1))
                        node.params.use_abs = use_abs
                    except:
                        y = np.array([np.nan]).repeat(X_idx.shape[0])
                    res.append(y)
            return res
        
        else:
            X_idx = X[tree_idx]
            tree = self.retrieve_tree(refinement_type=refinement_type, dataset_idx = tree_idx)
            if tree is not None:
                try:
                    #use abs
                    use_abs = tree.params.use_abs
                    tree.params.use_abs = True
                    y = tree.val(X_idx).reshape((-1, 1))
                    tree.params.use_abs = use_abs
                except:
                    y = np.array([np.nan]).repeat(X_idx.shape[0])
                return y
            else:
                return None